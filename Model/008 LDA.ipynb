{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'corpora' from 'gensim' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgensim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m corpora\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'corpora' from 'gensim' (unknown location)"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "!pip install pyLDAvis\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.gensim_models as pg\n",
    "import matplotlib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T06:13:00.023711Z",
     "start_time": "2024-05-23T06:13:00.021042Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Desktop/Spring 2024/POLI179/poli 179 data/People's daily/Train/final_data.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1ea5e711e99cc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stopwords_files = ['baidu_stopwords.txt', 'cn_stopwords.txt', \n",
    "                   'hit_stopwords.txt', 'scu_stopwords.txt']\n",
    "stopwords = set()\n",
    "for filename in stopwords_files:\n",
    "    file_path = os.path.join('/content/drive/My Drive/POLI/POLI179_final_project/Stopwords/', filename)\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "        stopwords.update([line.strip() for line in file.readlines()])\n",
    "        \n",
    "additional_stopwords = {'年', '月', '日', '第版', '说', '中', '更','年 月 日','月 日','时','我国','杨丽','总','这是','记者','做','里','一年','包括','年月日','一是',\n",
    "                        '二是','要','新','亿元','没','岁','想', '应','一种','郑', '走','老', '前','干','吃','越来越','记者','进一步','元','来到','找','事','带','买',\n",
    "                        '成','住','本版','本报记者','达','占','镇','村','名','区','来到','一条','建成','性','绣','黄花','去年','提出','介绍','出','搬','李心萍','万元',\n",
    "                        '亿元','万人','千人','周永康','嫌疑人','第一节','第二节','第三节','万亿元','加快','支农','出','水','据','一季度','二季度',\n",
    "                        '三季度','四季度','上年','比上','拉动','',''}  \n",
    "stopwords.update(additional_stopwords)\n",
    "\n",
    "print(\"Total stopwords loaded:\", len(stopwords))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7d0a3a68e935d78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    words = jieba.cut(text)\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return filtered_words\n",
    "data['segmented_text'] = data['TextBody'].apply(preprocess_text)\n",
    "dictionary = Dictionary(data['segmented_text'])\n",
    "corpus = [dictionary.doc2bow(text) for text in data['segmented_text']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5859848c9657a05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus=corpus, num_topics=5, id2word=dictionary, passes=30, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49700bb795770cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#计算困惑度\n",
    "def perplexity(num_topics):\n",
    "    ldamodel = LdaModel(corpus, num_topics=num_topics, id2word = dictionary, passes=30)\n",
    "    print(ldamodel.print_topics(num_topics=num_topics, num_words=15))\n",
    "    print(ldamodel.log_perplexity(corpus))\n",
    "    return ldamodel.log_perplexity(corpus)\n",
    "#计算coherence\n",
    "def coherence(num_topics):\n",
    "    ldamodel = LdaModel(corpus, num_topics=num_topics, id2word = dictionary, passes=30,random_state = 1)\n",
    "    print(ldamodel.print_topics(num_topics=num_topics, num_words=10))\n",
    "    ldacm = CoherenceModel(model=ldamodel, texts=data['segmented_text'], dictionary=dictionary, coherence='u_mass')\n",
    "    print(ldacm.get_coherence())\n",
    "    return ldacm.get_coherence()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f592244026565a31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = range(1,15)\n",
    "y = [coherence(i) for i in x]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('coherence')\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False\n",
    "plt.title('Topic-Coherence Change Trend')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da4f788634fe36cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = range(1,15)\n",
    "z = [perplexity(i) for i in x]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False\n",
    "plt.title('Topic-Perplexity Change Trend')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f99a7dbbc40341c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyLDAvis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd3a179a34120a21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize Topics\n",
    "vis_data = pg.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.save_html(vis_data, '/Plot/lda_visualization.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbd3be11dbdfae1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time Series LDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e45cd1d6fea24a01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming 'Year' is the column by which you'll segment your data\n",
    "grouped_data = data.groupby('Year')['TextBody'].apply(lambda texts: ' '.join(texts)).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fee2f6c2118f82d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_data['processed_text'] = grouped_data['TextBody'].apply(preprocess_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80ffccc2b63b1948"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(grouped_data['processed_text'])\n",
    "\n",
    "# Create corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in grouped_data['processed_text']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7a10fafcc045199"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Number of topics\n",
    "num_topics = 5\n",
    "\n",
    "# Train LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=15, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ec11a0019700f44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print topics for each time slice\n",
    "grouped_data['year_topics'] = grouped_data['processed_text'].apply(lambda doc: lda_model[dictionary.doc2bow(doc)])\n",
    "\n",
    "# Display the dominant topics for each year\n",
    "for year, topics in zip(grouped_data['Year'], grouped_data['year_topics']):\n",
    "    print(f\"\\nYear: {year}\")\n",
    "    pprint(sorted(topics, key=lambda x: x[1], reverse=True))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d81d4c6300a8799"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of topics\n",
    "num_topics = 5  # Change this based on your actual model\n",
    "\n",
    "# Initialize a list to hold the prevalence of each topic across years\n",
    "topic_prevalence = [[] for _ in range(num_topics)]\n",
    "years = grouped_data['Year'].tolist()  # Collect all years once, assuming it's the same for all entries\n",
    "\n",
    "for index, row in grouped_data.iterrows():\n",
    "    topic_distribution = dict(row['year_topics'])  # Assuming this is already a list of tuples (topic_id, topic_prob)\n",
    "    for topic_id in range(num_topics):\n",
    "        # Append the prevalence for each topic in its respective list\n",
    "        topic_prevalence[topic_id].append(topic_distribution.get(topic_id, 0))\n",
    "\n",
    "# Plot the prevalence of all topics over time\n",
    "plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "\n",
    "for topic_id in range(num_topics):\n",
    "    plt.plot(years, topic_prevalence[topic_id], marker='o', linestyle='-', label=f'Topic {topic_id}')\n",
    "\n",
    "plt.title('Trends of All Topics Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Topic Prevalence')\n",
    "plt.grid(True)\n",
    "plt.legend()  # Add a legend to identify each line\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51219e16c9fe3953"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Prepare the visualization data for PyLDAvis\n",
    "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "# Save the visualization as an HTML file\n",
    "output_path = '/content/drive/My Drive/POLI/POLI179_final_project/Output/yearlylda_visualization.html'\n",
    "pyLDAvis.save_html(vis, output_path)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "334ba18ce8e53280"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
